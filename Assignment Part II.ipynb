{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10dae836",
   "metadata": {},
   "source": [
    "## 1.Explore the YOLO model, understand how it works."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "1fec1107",
   "metadata": {},
   "source": [
    "1. Divide the WxH image into  SxS grid\n",
    "2. For each Grid:\n",
    "    \n",
    "    a. Detect B numbers of bounding box that contains an object\n",
    "    \n",
    "    b. Predict C condiction probability base on the trained class\n",
    "\n",
    "Architecture of model:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "*Redmon, Joseph, Santosh Divvala, Ross Girshick, and Ali Farhadi. \"You only look once: \n",
    "Unified, real-time object detection.\" In Proceedings of the IEEE conference on computer \n",
    "vision and pattern recognition, pp. 779-788. 2016.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e40f25",
   "metadata": {},
   "source": [
    "dataset:\n",
    "\n",
    "https://www.kaggle.com/datasets/snehilsanyal/construction-site-safety-image-dataset-roboflow/data\n",
    "\n",
    "implmentation:\n",
    "\n",
    "https://github.com/tanjeffreyz/yolo-v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a51309",
   "metadata": {},
   "source": [
    "## 2. Define your own object detection case. Get hands-on experience by training and testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56458ab6",
   "metadata": {},
   "source": [
    "Detection of construction site worker and their Personal Protective Equipment (PPE) for identification of site safety issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bcfd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from torchvision import models, datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e89c896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 135\n",
    "WARMUP_EPOCHS = 0\n",
    "LEARNING_RATE = 1E-4\n",
    "\n",
    "EPSILON = 1E-6\n",
    "IMAGE_SIZE = (448, 448)\n",
    "\n",
    "S = 7       # Divide each image into a SxS grid\n",
    "B = 2       # Number of bounding boxes to predict\n",
    "C = 10      # Number of classes in the dataset\n",
    "\n",
    "## about model\n",
    "num_classes = 10\n",
    "\n",
    "## about data\n",
    "data_dir = r\"./source/css-data/\" ## You may need to specify the data_dir first\n",
    "input_size = 448\n",
    "batch_size = 64\n",
    "\n",
    "## about training\n",
    "num_epochs = 50\n",
    "lr = 0.005\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35801c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class YOLOv1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.depth = B * 5 + C\n",
    "\n",
    "        layers = [\n",
    "            # Probe(0, forward=lambda x: print('#' * 5 + ' Start ' + '#' * 5)),\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),                   # Conv 1\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            # Probe('conv1', forward=probe_dist),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(64, 192, kernel_size=3, padding=1),                           # Conv 2\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            # Probe('conv2', forward=probe_dist),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(192, 128, kernel_size=1),                                     # Conv 3\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Conv2d(256, 256, kernel_size=1),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            # Probe('conv3', forward=probe_dist),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        ]\n",
    "\n",
    "        for i in range(4):                                                          # Conv 4\n",
    "            layers += [\n",
    "                nn.Conv2d(512, 256, kernel_size=1),\n",
    "                nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "                nn.LeakyReLU(negative_slope=0.1)\n",
    "            ]\n",
    "        layers += [\n",
    "            nn.Conv2d(512, 512, kernel_size=1),\n",
    "            nn.Conv2d(512, 1024, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            # Probe('conv4', forward=probe_dist),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        ]\n",
    "\n",
    "        for i in range(2):                                                          # Conv 5\n",
    "            layers += [\n",
    "                nn.Conv2d(1024, 512, kernel_size=1),\n",
    "                nn.Conv2d(512, 1024, kernel_size=3, padding=1),\n",
    "                nn.LeakyReLU(negative_slope=0.1)\n",
    "            ]\n",
    "        layers += [\n",
    "            nn.Conv2d(1024, 1024, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Conv2d(1024, 1024, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            # Probe('conv5', forward=probe_dist),\n",
    "        ]\n",
    "\n",
    "        for _ in range(2):                                                          # Conv 6\n",
    "            layers += [\n",
    "                nn.Conv2d(1024, 1024, kernel_size=3, padding=1),\n",
    "                nn.LeakyReLU(negative_slope=0.1)\n",
    "            ]\n",
    "        # layers.append(Probe('conv6', forward=probe_dist))\n",
    "\n",
    "        layers += [\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(S * S * 1024, 4096),                            # Linear 1\n",
    "            nn.Dropout(),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            # Probe('linear1', forward=probe_dist),\n",
    "            nn.Linear(4096, S * S * self.depth),                      # Linear 2\n",
    "            # Probe('linear2', forward=probe_dist),\n",
    "        ]\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.reshape(\n",
    "            self.model.forward(x),\n",
    "            (x.size(dim=0), S, S, self.depth)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6697410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "\n",
    "def bbox_to_coords(t):\n",
    "    \"\"\"Changes format of bounding boxes from [x, y, width, height] to ([x1, y1], [x2, y2]).\"\"\"\n",
    "\n",
    "    width = bbox_attr(t, 2)\n",
    "    x = bbox_attr(t, 0)\n",
    "    x1 = x - width / 2.0\n",
    "    x2 = x + width / 2.0\n",
    "\n",
    "    height = bbox_attr(t, 3)\n",
    "    y = bbox_attr(t, 1)\n",
    "    y1 = y - height / 2.0\n",
    "    y2 = y + height / 2.0\n",
    "\n",
    "    return torch.stack((x1, y1), dim=4), torch.stack((x2, y2), dim=4)\n",
    "\n",
    "def bbox_attr(data, i):\n",
    "    \"\"\"Returns the Ith attribute of each bounding box in data.\"\"\"\n",
    "\n",
    "    attr_start = C + i\n",
    "    return data[..., attr_start::5]\n",
    "\n",
    "\n",
    "def scale_bbox_coord(coord, center, scale):\n",
    "    return ((coord - center) * scale) + center\n",
    "\n",
    "def get_iou(p, a):\n",
    "    p_tl, p_br = bbox_to_coords(p)          # (batch, S, S, B, 2)\n",
    "    a_tl, a_br = bbox_to_coords(a)\n",
    "\n",
    "    # Largest top-left corner and smallest bottom-right corner give the intersection\n",
    "    coords_join_size = (-1, -1, -1, B, B, 2)\n",
    "    tl = torch.max(\n",
    "        p_tl.unsqueeze(4).expand(coords_join_size),         # (batch, S, S, B, 1, 2) -> (batch, S, S, B, B, 2)\n",
    "        a_tl.unsqueeze(3).expand(coords_join_size)          # (batch, S, S, 1, B, 2) -> (batch, S, S, B, B, 2)\n",
    "    )\n",
    "    br = torch.min(\n",
    "        p_br.unsqueeze(4).expand(coords_join_size),\n",
    "        a_br.unsqueeze(3).expand(coords_join_size)\n",
    "    )\n",
    "\n",
    "    intersection_sides = torch.clamp(br - tl, min=0.0)\n",
    "    intersection = intersection_sides[..., 0] \\\n",
    "                   * intersection_sides[..., 1]       # (batch, S, S, B, B)\n",
    "\n",
    "    p_area = bbox_attr(p, 2) * bbox_attr(p, 3)                  # (batch, S, S, B)\n",
    "    p_area = p_area.unsqueeze(4).expand_as(intersection)        # (batch, S, S, B, 1) -> (batch, S, S, B, B)\n",
    "\n",
    "    a_area = bbox_attr(a, 2) * bbox_attr(a, 3)                  # (batch, S, S, B)\n",
    "    a_area = a_area.unsqueeze(3).expand_as(intersection)        # (batch, S, S, 1, B) -> (batch, S, S, B, B)\n",
    "\n",
    "    union = p_area + a_area - intersection\n",
    "\n",
    "    # Catch division-by-zero\n",
    "    zero_unions = (union == 0.0)\n",
    "    union[zero_unions] = EPSILON\n",
    "    intersection[zero_unions] = 0.0\n",
    "\n",
    "    return intersection / union\n",
    "\n",
    "def get_dimensions(label):\n",
    "    size = label['annotation']['size']\n",
    "    return int(size['width']), int(size['height'])\n",
    "\n",
    "def get_bounding_boxes(label):\n",
    "    width, height = get_dimensions(label)\n",
    "    x_scale = IMAGE_SIZE[0] / width\n",
    "    y_scale = IMAGE_SIZE[1] / height\n",
    "    boxes = []\n",
    "    objects = label['annotation']['object']\n",
    "    for obj in objects:\n",
    "        box = obj['bndbox']\n",
    "        coords = (\n",
    "            int(int(box['xmin']) * x_scale),\n",
    "            int(int(box['xmax']) * x_scale),\n",
    "            int(int(box['ymin']) * y_scale),\n",
    "            int(int(box['ymax']) * y_scale)\n",
    "        )\n",
    "        name = obj['name']\n",
    "        boxes.append((name, coords))\n",
    "    return boxes\n",
    "\n",
    "\n",
    "class SumSquaredErrorLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l_coord = 5\n",
    "        self.l_noobj = 0.5\n",
    "\n",
    "    def forward(self, p, a):\n",
    "        # Calculate IOU of each predicted bbox against the ground truth bbox\n",
    "        iou = get_iou(p, a)                     # (batch, S, S, B, B)\n",
    "        max_iou = torch.max(iou, dim=-1)[0]     # (batch, S, S, B)\n",
    "\n",
    "        # Get masks\n",
    "        bbox_mask = bbox_attr(a, 4) > 0.0\n",
    "        p_template = bbox_attr(p, 4) > 0.0\n",
    "        obj_i = bbox_mask[..., 0:1]         # 1 if grid I has any object at all\n",
    "        responsible = torch.zeros_like(p_template).scatter_(       # (batch, S, S, B)\n",
    "            -1,\n",
    "            torch.argmax(max_iou, dim=-1, keepdim=True),                # (batch, S, S, B)\n",
    "            value=1                         # 1 if bounding box is \"responsible\" for predicting the object\n",
    "        )\n",
    "        obj_ij = obj_i * responsible        # 1 if object exists AND bbox is responsible\n",
    "        noobj_ij = ~obj_ij                  # Otherwise, confidence should be 0\n",
    "\n",
    "        # XY position losses\n",
    "        x_losses = mse_loss(\n",
    "            obj_ij * bbox_attr(p, 0),\n",
    "            obj_ij * bbox_attr(a, 0)\n",
    "        )\n",
    "        y_losses = mse_loss(\n",
    "            obj_ij * bbox_attr(p, 1),\n",
    "            obj_ij * bbox_attr(a, 1)\n",
    "        )\n",
    "        pos_losses = x_losses + y_losses\n",
    "        # print('pos_losses', pos_losses.item())\n",
    "\n",
    "        # Bbox dimension losses\n",
    "        p_width = bbox_attr(p, 2)\n",
    "        a_width = bbox_attr(a, 2)\n",
    "        width_losses = mse_loss(\n",
    "            obj_ij * torch.sign(p_width) * torch.sqrt(torch.abs(p_width) + EPSILON),\n",
    "            obj_ij * torch.sqrt(a_width)\n",
    "        )\n",
    "        p_height = bbox_attr(p, 3)\n",
    "        a_height = bbox_attr(a, 3)\n",
    "        height_losses = mse_loss(\n",
    "            obj_ij * torch.sign(p_height) * torch.sqrt(torch.abs(p_height) + EPSILON),\n",
    "            obj_ij * torch.sqrt(a_height)\n",
    "        )\n",
    "        dim_losses = width_losses + height_losses\n",
    "        # print('dim_losses', dim_losses.item())\n",
    "\n",
    "        # Confidence losses (target confidence is IOU)\n",
    "        obj_confidence_losses = mse_loss(\n",
    "            obj_ij * bbox_attr(p, 4),\n",
    "            obj_ij * torch.ones_like(max_iou)\n",
    "        )\n",
    "        # print('obj_confidence_losses', obj_confidence_losses.item())\n",
    "        noobj_confidence_losses = mse_loss(\n",
    "            noobj_ij * bbox_attr(p, 4),\n",
    "            torch.zeros_like(max_iou)\n",
    "        )\n",
    "        # print('noobj_confidence_losses', noobj_confidence_losses.item())\n",
    "\n",
    "        # Classification losses\n",
    "        class_losses = mse_loss(\n",
    "            obj_i * p[..., :C],\n",
    "            obj_i * a[..., :C]\n",
    "        )\n",
    "        # print('class_losses', class_losses.item())\n",
    "\n",
    "        total = self.l_coord * (pos_losses + dim_losses) \\\n",
    "                + obj_confidence_losses \\\n",
    "                + self.l_noobj * noobj_confidence_losses \\\n",
    "                + class_losses\n",
    "        return total / BATCH_SIZE\n",
    "\n",
    "\n",
    "def mse_loss(a, b):\n",
    "    flattened_a = torch.flatten(a, end_dim=-2)\n",
    "    flattened_b = torch.flatten(b, end_dim=-2).expand_as(flattened_a)\n",
    "    return F.mse_loss(\n",
    "        flattened_a,\n",
    "        flattened_b,\n",
    "        reduction='sum'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cb5ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset for object detection (Roboflow YOLO labels)\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "# Small transform to randomly adjust exposure(V) and saturation(S) in HSV space\n",
    "class RandomHSV:\n",
    "    def __init__(self, exposure_factor: float = 1.5, saturation_factor: float = 1.5):\n",
    "        self.exposure_factor = float(exposure_factor)\n",
    "        self.saturation_factor = float(saturation_factor)\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # img: PIL.Image in RGB\n",
    "        import random\n",
    "        import numpy as _np\n",
    "        from PIL import Image\n",
    "\n",
    "        hsv = img.convert('HSV')\n",
    "        h, s, v = hsv.split()\n",
    "\n",
    "        f_e = random.uniform(1.0 / self.exposure_factor, self.exposure_factor)\n",
    "        f_s = random.uniform(1.0 / self.saturation_factor, self.saturation_factor)\n",
    "\n",
    "        s_arr = _np.array(s).astype(_np.float32)\n",
    "        v_arr = _np.array(v).astype(_np.float32)\n",
    "\n",
    "        s_arr = _np.clip(s_arr * f_s, 0, 255).astype(_np.uint8)\n",
    "        v_arr = _np.clip(v_arr * f_e, 0, 255).astype(_np.uint8)\n",
    "\n",
    "        s2 = Image.fromarray(s_arr, mode='L')\n",
    "        v2 = Image.fromarray(v_arr, mode='L')\n",
    "        hsv2 = Image.merge('HSV', (h, s2, v2))\n",
    "        return hsv2.convert('RGB')\n",
    "\n",
    "\n",
    "class YOLODataset(Dataset):\n",
    "    \"\"\"\n",
    "    A Dataset that reads images and Roboflow-exported YOLO label .txt files.\n",
    "    Assumes directory layout:\n",
    "      root_dir/\n",
    "        train|valid|test/\n",
    "          images/*.jpg|.png|.jpeg\n",
    "          labels/*.txt  (same stem as image)\n",
    "\n",
    "    Label file format (per line):\n",
    "      <class_id> <x_center> <y_center> <width> <height>\n",
    "    where all bbox coordinates are normalized to [0, 1] relative to image size.\n",
    "    \"\"\"\n",
    "\n",
    "    IMG_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n",
    "\n",
    "    def __init__(self, root_dir: str, split: str = \"train\", input_size: int = 64, transform=None):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.split = split\n",
    "        self.images_dir = self.root_dir / split / \"images\"\n",
    "        self.labels_dir = self.root_dir / split / \"labels\"\n",
    "        self.classes_dir = self.root_dir /  \"classes.json\"\n",
    "        self.input_size = input_size\n",
    "\n",
    "        if transform is None:\n",
    "            # Augmentation pipeline:\n",
    "            # - RandomAffine: translate up to 20% and scale +/-20%\n",
    "            # - RandomHSV: random exposure & saturation scaling (factor up to 1.5)\n",
    "            # - Resize -> ToTensor -> RandomErasing used as a dropout with p=0.5\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
    "                RandomHSV(exposure_factor=1.5, saturation_factor=1.5),\n",
    "                transforms.Resize((input_size, input_size)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.RandomErasing(p=0.5, value=0)\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transform\n",
    "\n",
    "        # Gather image files\n",
    "        self.image_paths = []\n",
    "        for ext in self.IMG_EXTS:\n",
    "            self.image_paths.extend(sorted(self.images_dir.glob(f\"*{ext}\")))\n",
    "\n",
    "        # Load class names (list of class strings)\n",
    "        with open(self.classes_dir, \"r\") as f:\n",
    "            class_list = json.load(f)\n",
    "        # Map class name -> id\n",
    "        self.class_to_idx = {name: idx for idx, name in enumerate(class_list)}\n",
    "\n",
    "        if len(self.image_paths) == 0:\n",
    "            raise FileNotFoundError(f\"No images found in {self.images_dir}\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def _read_labels(self, label_path: Path) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Read YOLO txt label file. Returns (labels, boxes) where:\n",
    "          - labels: (N,) int64 tensor of class ids\n",
    "          - boxes: (N, 4) float32 tensor of [x_center, y_center, width, height] normalized to [0,1]\n",
    "        If no file or empty, returns empty tensors with right shapes.\n",
    "        \"\"\"\n",
    "        if not label_path.exists():\n",
    "            return torch.zeros((0,), dtype=torch.long), torch.zeros((0, 4), dtype=torch.float32)\n",
    "\n",
    "        labels: List[int] = []\n",
    "        boxes: List[List[float]] = []\n",
    "        with open(label_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                parts = line.split()\n",
    "                if len(parts) != 5:\n",
    "                    # Skip malformed lines safely\n",
    "                    continue\n",
    "                cls_id, x_c, y_c, w, h = parts\n",
    "                try:\n",
    "                    labels.append(int(float(cls_id)))\n",
    "                    boxes.append([float(x_c), float(y_c), float(w), float(h)])\n",
    "                except ValueError:\n",
    "                    # Skip rows with invalid numbers\n",
    "                    continue\n",
    "\n",
    "        if len(labels) == 0:\n",
    "            return torch.zeros((0,), dtype=torch.long), torch.zeros((0, 4), dtype=torch.float32)\n",
    "\n",
    "        return torch.tensor(labels, dtype=torch.long), torch.tensor(boxes, dtype=torch.float32)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        img_path: Path = self.image_paths[idx]\n",
    "        label_path = self.labels_dir / (img_path.stem + \".txt\")\n",
    "\n",
    "        # Load image\n",
    "        with Image.open(img_path) as img:\n",
    "            img = img.convert(\"RGB\")\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # Load labels (normalized YOLO format)\n",
    "        labels, coords = self._read_labels(label_path)\n",
    "\n",
    "        # Build target dictionary (kept for potential future use)\n",
    "        target: Dict[str, torch.Tensor] = {\n",
    "            \"labels\": labels,          # (N,)\n",
    "            \"boxes_yolo\": coords,       # (N, 4) normalized [x_c, y_c, w, h]\n",
    "            \"image_id\": torch.tensor([idx], dtype=torch.int64),\n",
    "            \"orig_path\": str(img_path),\n",
    "        }\n",
    "\n",
    "        # Build YOLOv1-style ground truth tensor of shape (S, S, 5*B + C)\n",
    "        original_data = img\n",
    "        width = original_data.size(dim=2)\n",
    "        height = original_data.size(dim=1)\n",
    "        grid_size_x = width / S   # (W / S)\n",
    "        grid_size_y = height / S  # (H / S)\n",
    "\n",
    "        boxes_count_in_cell: Dict[Tuple[int, int], int] = {}\n",
    "        depth = 5 * B + C\n",
    "        ground_truth = torch.zeros((S, S, depth), dtype=torch.float32)\n",
    "\n",
    "        # Iterate all labeled boxes for this image\n",
    "        # coords are normalized to [0,1]: (xc, yc, w, h)\n",
    "        for class_idx, (xc, yc, bw, bh) in zip(labels.tolist(), coords.tolist()):\n",
    "            # Convert center to pixel coords to choose the grid cell, but keep normalized values in tensor\n",
    "            mid_x = xc * width\n",
    "            mid_y = yc * height\n",
    "            col = int(mid_x // grid_size_x)\n",
    "            row = int(mid_y // grid_size_y)\n",
    "\n",
    "            if 0 <= col < S and 0 <= row < S:\n",
    "                cell = (row, col)\n",
    "\n",
    "                # Class one-hot for this cell\n",
    "                one_hot = torch.zeros(C, dtype=torch.float32)\n",
    "                if 0 <= class_idx < C:\n",
    "                    one_hot[class_idx] = 1.0\n",
    "                ground_truth[row, col, :C] = one_hot\n",
    "\n",
    "                # Which bbox slot to use in this cell\n",
    "                bbox_index = boxes_count_in_cell.get(cell, 0)\n",
    "                if bbox_index < B:\n",
    "                    # Store bbox as normalized image coords (xc, yc, w, h) and confidence 1.0\n",
    "                    # Keep xc, yc, w, h in [0,1] to be consistent and avoid negatives\n",
    "                    bbox_truth = torch.tensor((xc, yc, bw, bh, 1.0), dtype=torch.float32)\n",
    "                    start = C + bbox_index * 5\n",
    "                    end = start + 5\n",
    "                    ground_truth[row, col, start:end] = bbox_truth\n",
    "                    boxes_count_in_cell[cell] = bbox_index + 1\n",
    "\n",
    "        # Return image and dense ground-truth tensor\n",
    "        return img, ground_truth, original_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff9ba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note that: here we provide a basic solution for training and validation.\n",
    "## You can directly change it if you find something wrong or not good enough.\n",
    "\n",
    "def train_model(model, train_loader, valid_loader, loss_function, optimizer, device, num_epochs=20):        \n",
    "    \"\"\"\n",
    "    Train the YOLOv1-style detector with SumSquaredErrorLoss.\n",
    "    - Computes a simple proxy metric: per-cell class accuracy on cells that contain objects.\n",
    "    - Adds NaN guards to avoid corrupting weights if the loss becomes invalid.\n",
    "    \"\"\"\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # train the model\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for data, labels in train_loader:\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model.forward(data)\n",
    "            loss = loss_function(predictions, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() / len(train_loader)\n",
    "            del data, labels\n",
    "\n",
    "        # Step and graph scheduler once an epoch\n",
    "        # writer.add_scalar('Learning Rate', scheduler.get_last_lr()[0], epoch)\n",
    "        # scheduler.step()\n",
    "\n",
    "\n",
    "        if epoch % 4 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                test_loss = 0\n",
    "                for data, labels in valid_loader:\n",
    "                    data = data.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    predictions = model.forward(data)\n",
    "                    loss = loss_function(predictions, labels)\n",
    "\n",
    "                    test_loss += loss.item() / len(valid_loader)\n",
    "                    del data, labels\n",
    "\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "                      f\"Train Loss: {train_loss:.4f}, \"\n",
    "                      f\"Valid Loss: {test_loss:.4f}\")\n",
    "\n",
    "    torch.save(model, 'best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac7a922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "def visualize_random_from_loader(loader, class_names=None):\n",
    "    \"\"\"\n",
    "    Visualize a random image from the detection DataLoader built by `load_yolo_data`.\n",
    "\n",
    "    Expects batches like:\n",
    "      imgs:    (B, 3, H, W)\n",
    "      targets: (B, S, S, C + 5*B) where for each cell and for each bbox slot k:\n",
    "                [xc, yc, w, h, conf] are normalized to [0,1] over the full image\n",
    "                and classes are one-hot in the first C channels.\n",
    "\n",
    "    Draws all GT boxes (cells whose conf > 0 in any bbox slot) on the image and\n",
    "    annotates with the cell's class if provided.\n",
    "    \"\"\"\n",
    "    imgs, targets = next(iter(loader))\n",
    "    b = imgs.shape[0]\n",
    "    if b == 0:\n",
    "        print('Empty batch from loader; nothing to visualize.')\n",
    "        return\n",
    "\n",
    "    idx = random.randrange(b)\n",
    "    img = imgs[idx]\n",
    "    gt = targets[idx]  # (S, S, C + 5*B)\n",
    "\n",
    "    H, W = img.shape[1], img.shape[2]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "    ax.imshow(img.permute(1, 2, 0).numpy())\n",
    "\n",
    "    any_box = False\n",
    "    for row in range(S):\n",
    "        for col in range(S):\n",
    "            # Determine class for this cell (if any)\n",
    "            cell_classes = gt[row, col, :C]\n",
    "            cls_id = int(cell_classes.argmax().item()) if cell_classes.max().item() > 0 else None\n",
    "\n",
    "            # Iterate over B bbox slots\n",
    "            for k in range(B):\n",
    "                start = C + k * 5\n",
    "                xc = float(gt[row, col, start + 0].item())\n",
    "                yc = float(gt[row, col, start + 1].item())\n",
    "                w  = float(gt[row, col, start + 2].item())\n",
    "                h  = float(gt[row, col, start + 3].item())\n",
    "                conf = float(gt[row, col, start + 4].item())\n",
    "\n",
    "                if conf <= 0:\n",
    "                    continue\n",
    "\n",
    "                any_box = True\n",
    "                x1 = (xc - w / 2.0) * W\n",
    "                y1 = (yc - h / 2.0) * H\n",
    "                rect = patches.Rectangle((x1, y1), w * W, h * H, linewidth=2, edgecolor='lime', facecolor='none')\n",
    "                ax.add_patch(rect)\n",
    "\n",
    "                if cls_id is not None:\n",
    "                    label_txt = class_names[cls_id] if class_names and 0 <= cls_id < len(class_names) else f\"cls {cls_id}\"\n",
    "                    ax.text(x1, max(0, y1 - 3), label_txt, color='yellow', fontsize=10,\n",
    "                            bbox=dict(facecolor='black', alpha=0.5, pad=1))\n",
    "\n",
    "    if not any_box:\n",
    "        ax.text(5, 15, \"No GT boxes in sample\", color='red', fontsize=12,\n",
    "                bbox=dict(facecolor='white', alpha=0.7, pad=2))\n",
    "\n",
    "    ax.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd4b071",
   "metadata": {},
   "source": [
    "## Below start to run functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7576bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model initialization\n",
    "model = YOLOv1()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device:', device)\n",
    "model = model.to(device)\n",
    "\n",
    "## optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "## loss function\n",
    "criterion = SumSquaredErrorLoss()\n",
    "\n",
    "## detection data preparation for visualization only\n",
    "yolo_train_loader, yolo_valid_loader = load_yolo_data(data_dir=data_dir, input_size=input_size, batch_size=8)\n",
    "visualize_random_from_loader(yolo_train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1f0325",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_model(model, yolo_train_loader, yolo_valid_loader, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d7a9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize validation results\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "def visualize_validation_results(model, valid_loader, class_names=None, device=None, n_images=8, conf_thresh=0.3):\n",
    "    \"\"\"\n",
    "    Visualize validation samples for the YOLOv1-style model with new loader outputs.\n",
    "\n",
    "    Inputs:\n",
    "      - model: produces outputs of shape (B, S, S, C + 5*B)\n",
    "      - valid_loader: yields (imgs, targets) where\n",
    "            imgs:    (B, 3, H, W)\n",
    "            targets: (B, S, S, C + 5*B)\n",
    "      - class_names: list of length C (optional)\n",
    "      - device: torch device\n",
    "      - n_images: number of images to preview from the batch\n",
    "      - conf_thresh: threshold to draw predicted boxes for any bbox slot\n",
    "\n",
    "    Drawing:\n",
    "      - Green boxes: Ground-truth from targets (confidence > 0)\n",
    "      - Red boxes: Predictions from model (confidence >= conf_thresh)\n",
    "      - Title: Top-1 predicted class for the image (derived by summing per-cell class logits)\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Get a single batch\n",
    "    imgs, targets = next(iter(valid_loader))\n",
    "    imgs = imgs.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(imgs)  # (B, S, S, C + 5*B)\n",
    "\n",
    "    # Move to CPU for plotting\n",
    "    imgs_cpu = imgs.cpu()\n",
    "    targets_cpu = targets.cpu()\n",
    "    outputs_cpu = outputs.cpu()\n",
    "\n",
    "    batch_size = imgs_cpu.shape[0]\n",
    "    n_show = int(min(n_images, batch_size))\n",
    "\n",
    "    fig_cols = 4\n",
    "    fig_rows = int(np.ceil(n_show / fig_cols))\n",
    "    fig, axes = plt.subplots(fig_rows, fig_cols, figsize=(4 * fig_cols, 3.5 * fig_rows))\n",
    "    if isinstance(axes, np.ndarray):\n",
    "        axes = axes.flatten()\n",
    "    else:\n",
    "        axes = [axes]\n",
    "\n",
    "    # Helper to safely clamp to [0,1]\n",
    "    def clamp01(x):\n",
    "        return max(0.0, min(1.0, float(x)))\n",
    "\n",
    "    # Title prediction: aggregate class logits over all cells\n",
    "    def image_top1_class(pred):\n",
    "        # pred: (S, S, C + 5*B)\n",
    "        class_logits = pred[..., :C]  # (S,S,C)\n",
    "        summed = class_logits.sum(dim=(0, 1))  # (C,)\n",
    "        return int(torch.argmax(summed).item()), float(torch.softmax(summed, dim=0).max().item())\n",
    "\n",
    "    for i in range(n_show):\n",
    "        ax = axes[i]\n",
    "        img = imgs_cpu[i].permute(1, 2, 0).numpy()\n",
    "        H, W = img.shape[:2]\n",
    "        gt = targets_cpu[i]       # (S,S,C+5B)\n",
    "        pred = outputs_cpu[i]     # (S,S,C+5B)\n",
    "\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Title from aggregated class prediction\n",
    "        top_cls, top_score = image_top1_class(pred)\n",
    "        ptxt = (class_names[top_cls] if class_names and 0 <= top_cls < len(class_names) else f'class {top_cls}')\n",
    "        ax.set_title(f'Pred top1: {ptxt} ({top_score:.2f})', color='white', fontsize=10, pad=3,\n",
    "                     backgroundcolor='black')\n",
    "\n",
    "        # Draw GT boxes (green)\n",
    "        any_gt = False\n",
    "        for row in range(S):\n",
    "            for col in range(S):\n",
    "                # cell class (for label)\n",
    "                cell_classes = gt[row, col, :C]\n",
    "                gt_cls = int(cell_classes.argmax().item()) if cell_classes.max().item() > 0 else None\n",
    "                # boxes\n",
    "                for k in range(B):\n",
    "                    s = C + 5 * k\n",
    "                    gxc, gyc, gw, gh, gconf = [float(gt[row, col, s + t].item()) for t in range(5)]\n",
    "                    if gconf <= 0:\n",
    "                        continue\n",
    "                    any_gt = True\n",
    "                    x1 = (gxc - gw / 2.0) * W\n",
    "                    y1 = (gyc - gh / 2.0) * H\n",
    "                    rect = patches.Rectangle((x1, y1), gw * W, gh * H, linewidth=2, edgecolor='lime', facecolor='none')\n",
    "                    ax.add_patch(rect)\n",
    "                    if gt_cls is not None:\n",
    "                        gtxt = class_names[gt_cls] if class_names and 0 <= gt_cls < len(class_names) else f'gt {gt_cls}'\n",
    "                        ax.text(x1, max(0, y1 - 5), gtxt, color='yellow', fontsize=9,\n",
    "                                bbox=dict(facecolor='black', alpha=0.6, pad=1))\n",
    "\n",
    "        # Draw predicted boxes (red) for slots with confidence >= threshold\n",
    "        any_pred = False\n",
    "        for row in range(S):\n",
    "            for col in range(S):\n",
    "                # Predicted class per cell (for label)\n",
    "                cell_logits = pred[row, col, :C]\n",
    "                p_cls = int(torch.argmax(cell_logits).item())\n",
    "                # For each bbox slot\n",
    "                for k in range(B):\n",
    "                    s = C + 5 * k\n",
    "                    pxc = clamp01(pred[row, col, s + 0].item())\n",
    "                    pyc = clamp01(pred[row, col, s + 1].item())\n",
    "                    pw  = clamp01(abs(pred[row, col, s + 2].item()))\n",
    "                    ph  = clamp01(abs(pred[row, col, s + 3].item()))\n",
    "                    pconf = float(pred[row, col, s + 4].item())\n",
    "                    if pconf < conf_thresh:\n",
    "                        continue\n",
    "                    any_pred = True\n",
    "                    x1 = (pxc - pw / 2.0) * W\n",
    "                    y1 = (pyc - ph / 2.0) * H\n",
    "                    rect = patches.Rectangle((x1, y1), pw * W, ph * H, linewidth=1.5, edgecolor='red', facecolor='none', linestyle='--')\n",
    "                    ax.add_patch(rect)\n",
    "                    ptxt = class_names[p_cls] if class_names and 0 <= p_cls < len(class_names) else f'pred {p_cls}'\n",
    "                    ax.text(x1, min(H - 2, y1 + 12), f'{ptxt} {pconf:.2f}', color='white', fontsize=8,\n",
    "                            bbox=dict(facecolor='red', alpha=0.5, pad=1))\n",
    "\n",
    "        if not any_gt and not any_pred:\n",
    "            ax.text(5, 15, 'No GT/Pred boxes', color='white', fontsize=10,\n",
    "                    bbox=dict(facecolor='black', alpha=0.6, pad=1))\n",
    "\n",
    "    # Hide unused axes\n",
    "    for k in range(n_show, len(axes)):\n",
    "        axes[k].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Load best model if available; else use current `model`\n",
    "model_to_eval = model\n",
    "best_model_path = 'best_model.pt'\n",
    "if os.path.exists(best_model_path):\n",
    "    try:\n",
    "        model_to_eval = torch.load(best_model_path, map_location=device, weights_only=False)\n",
    "        model_to_eval = model_to_eval.to(device)\n",
    "        print('Loaded best model from', best_model_path)\n",
    "    except Exception as e:\n",
    "        print('Could not load best model, using current model. Reason:', e)\n",
    "\n",
    "\n",
    "# Visualize a few validation samples\n",
    "visualize_validation_results(model_to_eval, yolo_valid_loader, class_names=class_names, device=device, n_images=8, conf_thresh=0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
